{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final face project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLo+paiEdikPlvMtwmh5jP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atulcoin/Simple-Face-Recognition-/blob/master/final_face_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rskV1UqV3MM"
      },
      "source": [
        "!pip install pafy\n",
        "!pip install imutils pafy youtube-dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZqZyWkYWLYV"
      },
      "source": [
        "import imutils\n",
        "import cv2\n",
        "import pafy\n",
        "import youtube_dl\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYmvK5crWXQ3"
      },
      "source": [
        "url = \"https://www.youtube.com/watch?v=hoNb6HuNmU0\"\n",
        "vPafy = pafy.new(url)\n",
        "\n",
        "play = vPafy.getbest(preftype=\"mp4\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0bEq-4oWbaY"
      },
      "source": [
        "cap = cv2.VideoCapture(play.url)\n",
        "print(cap.isOpened()) # if in cap we have entered wrong file path then it will give false else true\n",
        "while(cap.isOpened()):    # TO CAPTURE FRAMES OF CAMERA TO VIEW AS VIDEO \n",
        "  #  print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # TO PRINT HEIGHT or property OF THE FRAME \n",
        "  #  print(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # TO PRINT WIDTHE OF THE FRAME \n",
        "    face_dec = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "    ret, frame= cap.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # here i am printing gray image as output\n",
        "    faces = face_dec.detectMultiScale(gray, scaleFactor =1.05, minNeighbors=5)\n",
        "\n",
        "    for x,y,w,h in faces:\n",
        "        gray = cv2.rectangle(gray, (x,y), (x+w,y+h), (0,255,0),2)\n",
        "        cv2_imshow(gray)\n",
        "    if cv2.waitKey(1) == 13:  #13 is the asci code of enter key\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0t07z1Gn_38"
      },
      "source": [
        "training of model with custom data set\n",
        "**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91UpJplsrkJu",
        "outputId": "fbae162a-8d6a-460c-e2be-c8b33b3fecbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ads9PHyrW2xR"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "bpath = '/content/drive/My Drive/part1face'\n",
        "image_dir = os.path.join(bpath, \"train\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1iUs8KRpKoM",
        "outputId": "1ff2d1c4-2e00-4d91-85ac-46edc2b259b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_label = []\n",
        "x_train = []\n",
        "\n",
        "#count = 0\n",
        "\n",
        "current_id=0\n",
        "label_id={}\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(image_dir):\n",
        "  for file in files:\n",
        "    if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
        "      label = os.path.basename(root).replace(\" \",\"-\").lower() #we can replace os.path.dirname(path) with root also\n",
        "      path = os.path.join(root,file)\n",
        "            #print(label,path)\n",
        "            \n",
        "      if not label in label_id:\n",
        "        label_id[label] = current_id\n",
        "        current_id +=1\n",
        "      id_= label_id[label]\n",
        "      print(id_)\n",
        "        #img = cv2.imread(path, 1)\n",
        "      pil_image=  Image.open(path).convert(\"L\") # L to convert image in grey pil image is used to tell sysetem that the file in location is image file\n",
        "      image_arra=  np.array(pil_image,\"uint8\")\n",
        "            #print(image_arra)\n",
        "            \n",
        "      y_label.append(id_)\n",
        "      x_train.append(image_arra)\n",
        "y_label = np.asarray(y_label, dtype=np.int32)\n",
        "x_train = np.asarray(x_train, dtype=np.int32)\n",
        "#model = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "#model.train(np.asarray(x_train), np.asarray(y_label))\n",
        "#with open(\"labels.pickle\", 'wb') as f:\n",
        "   # pickle.dump(label_id, f)\n",
        "print(\"train complete\")\n",
        "print(x_train)\n",
        "#model.save('save_face.xml')\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "train complete\n",
            "[[[ 23  23  23 ... 237 234 232]\n",
            "  [ 22  22  23 ... 236 234 233]\n",
            "  [ 21  21  22 ... 236 236 237]\n",
            "  ...\n",
            "  [252 252 251 ... 115 146 177]\n",
            "  [252 251 252 ...  95 119 142]\n",
            "  [251 251 252 ...  82 101 108]]\n",
            "\n",
            " [[ 22  22  22 ... 238 237 236]\n",
            "  [ 22  22  22 ... 238 237 237]\n",
            "  [ 22  22  22 ... 238 237 237]\n",
            "  ...\n",
            "  [251 251 251 ...  90 110 146]\n",
            "  [252 252 251 ...  88 114 145]\n",
            "  [253 252 252 ...  94 115 137]]\n",
            "\n",
            " [[ 22  22  22 ... 144 126 107]\n",
            "  [ 22  22  22 ... 144 124 104]\n",
            "  [ 22  22  22 ... 146 123 103]\n",
            "  ...\n",
            "  [250 250 251 ...  83  95 111]\n",
            "  [250 249 249 ...  69  80  94]\n",
            "  [250 248 249 ...  66  69  93]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 26  26  26 ...  22  22  22]\n",
            "  [ 25  25  25 ...  22  22  22]\n",
            "  [ 25  25  25 ...  22  22  22]\n",
            "  ...\n",
            "  [ 19  19  18 ...  18  19  19]\n",
            "  [ 19  18  18 ...  18  18  19]\n",
            "  [ 20  19  17 ...  18  18  18]]\n",
            "\n",
            " [[ 25  25  25 ...  22  22  22]\n",
            "  [ 25  25  25 ...  22  22  22]\n",
            "  [ 25  25  25 ...  22  22  22]\n",
            "  ...\n",
            "  [ 18  18  18 ...  17  16  16]\n",
            "  [ 18  18  18 ...  17  17  17]\n",
            "  [ 18  18  18 ...  18  18  18]]\n",
            "\n",
            " [[ 26  26  26 ...  22  22  21]\n",
            "  [ 26  26  26 ...  22  22  22]\n",
            "  [ 26  26  26 ...  22  22  22]\n",
            "  ...\n",
            "  [ 18  18  18 ...  17  17  17]\n",
            "  [ 18  19  19 ...  17  17  17]\n",
            "  [ 19  19  19 ...  17  17  17]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWeW8J1itdIS",
        "outputId": "2e298c23-9ec3-4da7-b155-2d36ab2769cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(396, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lsyB3hGvGU3",
        "outputId": "3bd8b952-1070-45c5-8e53-faab8db86ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "396"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvZRcAN6vTlR"
      },
      "source": [
        "x_train = np.array(x_train)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX31Lj50wbuX",
        "outputId": "cb69cd97-d1bd-46f1-9680-a2018075a843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(396, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIaRr6yPwlX6"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "#y_label =y_label.astype('float32')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRO2Tw4uTLzS",
        "outputId": "4e22fe24-e487-4bd3-a10a-ee1ae6fe3b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(396, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmbTvhrVTQyn",
        "outputId": "9d24cc14-6ece-4254-b113-73bed3f523ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.ndim"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5IC0uihTeTz"
      },
      "source": [
        "x_train = np.expand_dims(x_train, -1)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPMsMz-ITuzf",
        "outputId": "67a4ed34-2d6b-4ed5-b9df-c8e5ef29bd98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.ndim"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYIJX8u-x2el"
      },
      "source": [
        "x_train /= 255\n",
        "#y_label /=255"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADVeTxUCx76u"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao5dUMe3y3l2"
      },
      "source": [
        "creating validation data set for validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZDfg5ubyDqa"
      },
      "source": [
        "bpath = '/content/drive/My Drive/part1face'\n",
        "image_dir = os.path.join(bpath, \"validation\")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml2qrf61y1lL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaW8wbVTyi4_",
        "outputId": "6bd60c7d-01d6-4a59-f986-521fc7309af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_vali = []\n",
        "x_vali = []\n",
        "\n",
        "#count = 0\n",
        "\n",
        "current_id=0\n",
        "label_id={}\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(image_dir):\n",
        "  for file in files:\n",
        "    if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
        "      label = os.path.basename(root).replace(\" \",\"-\").lower() #we can replace os.path.dirname(path) with root also\n",
        "      path = os.path.join(root,file)\n",
        "            #print(label,path)\n",
        "            \n",
        "      if not label in label_id:\n",
        "        label_id[label] = current_id\n",
        "        current_id +=1\n",
        "      id_= label_id[label]\n",
        "      print(id_)\n",
        "        #img = cv2.imread(path, 1)\n",
        "      pil_image=  Image.open(path).convert(\"L\") # L to convert image in grey pil image is used to tell sysetem that the file in location is image file\n",
        "      image_arra=  np.array(pil_image,\"uint8\")\n",
        "            #print(image_arra)\n",
        "            \n",
        "      y_vali.append(id_)\n",
        "      x_vali.append(image_arra)\n",
        "y_vali = np.asarray(y_vali, dtype=np.int32)\n",
        "x_vali = np.asarray(x_vali, dtype=np.int32)\n",
        "#model = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "#model.train(np.asarray(x_train), np.asarray(y_label))\n",
        "#with open(\"labels.pickle\", 'wb') as f:\n",
        "   # pickle.dump(label_id, f)\n",
        "print(\"validation data complete\")\n",
        "print(x_vali)\n",
        "#model.save('save_face.xml')\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "validation data complete\n",
            "[[[128 133 139 ... 105 112 111]\n",
            "  [127 132 138 ... 105 109 109]\n",
            "  [128 132 138 ...  99 104 106]\n",
            "  ...\n",
            "  [ 55  59  68 ...  38  37  37]\n",
            "  [ 57  60  70 ...  38  38  38]\n",
            "  [ 58  61  70 ...  39  38  38]]\n",
            "\n",
            " [[ 26  26  26 ...  22  22  22]\n",
            "  [ 26  25  25 ...  22  22  22]\n",
            "  [ 26  25  25 ...  22  22  22]\n",
            "  ...\n",
            "  [ 18  18  18 ...  17  17  17]\n",
            "  [ 17  17  17 ...  18  18  17]\n",
            "  [ 17  17  17 ...  19  18  18]]\n",
            "\n",
            " [[136 138 134 ... 129 111 101]\n",
            "  [134 137 137 ... 140 121 110]\n",
            "  [133 137 138 ... 162 142 131]\n",
            "  ...\n",
            "  [ 56  56  55 ...  40  40  40]\n",
            "  [ 61  60  59 ...  40  40  40]\n",
            "  [ 65  64  62 ...  40  40  40]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 29  29  29 ...  97  97  97]\n",
            "  [ 29  29  29 ...  97  97  97]\n",
            "  [ 29  29  29 ...  97  97  97]\n",
            "  ...\n",
            "  [117 117 117 ... 147 147 147]\n",
            "  [117 118 117 ... 147 147 147]\n",
            "  [118 118 117 ... 147 147 147]]\n",
            "\n",
            " [[ 72  73  73 ... 148 148 148]\n",
            "  [ 72  73  73 ... 148 148 148]\n",
            "  [ 72  72  72 ... 148 148 148]\n",
            "  ...\n",
            "  [115 115 114 ... 202 201 201]\n",
            "  [116 115 115 ... 201 201 201]\n",
            "  [116 116 115 ... 201 201 201]]\n",
            "\n",
            " [[ 39  39  38 ... 252 252 253]\n",
            "  [ 39  39  38 ... 252 252 252]\n",
            "  [ 39  39  38 ... 251 252 252]\n",
            "  ...\n",
            "  [ 67  67  67 ... 255 255 255]\n",
            "  [ 67  67  67 ... 255 255 255]\n",
            "  [ 67  67  67 ... 255 255 255]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDWvCQEyzmxr"
      },
      "source": [
        "x_vali = x_vali.astype('float32')\n",
        "#y_vali =y_vali.astype('float32')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seux71qwUH42"
      },
      "source": [
        "x_vali = np.expand_dims(x_vali, -1)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAf02oYQz4po"
      },
      "source": [
        "x_vali /= 255\n",
        "#y_vali /=255"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT0FScOb10dY"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWqYhE493Vbr",
        "outputId": "273067f3-324e-404c-caf4-4ef2ccd38d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SObKgI1_gaH",
        "outputId": "e28976eb-09d7-4c41-e7e9-278d83146b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.09019608],\n",
              "        [0.09019608],\n",
              "        [0.09019608],\n",
              "        ...,\n",
              "        [0.92941177],\n",
              "        [0.91764706],\n",
              "        [0.9098039 ]],\n",
              "\n",
              "       [[0.08627451],\n",
              "        [0.08627451],\n",
              "        [0.09019608],\n",
              "        ...,\n",
              "        [0.9254902 ],\n",
              "        [0.91764706],\n",
              "        [0.9137255 ]],\n",
              "\n",
              "       [[0.08235294],\n",
              "        [0.08235294],\n",
              "        [0.08627451],\n",
              "        ...,\n",
              "        [0.9254902 ],\n",
              "        [0.9254902 ],\n",
              "        [0.92941177]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.9882353 ],\n",
              "        [0.9882353 ],\n",
              "        [0.9843137 ],\n",
              "        ...,\n",
              "        [0.4509804 ],\n",
              "        [0.57254905],\n",
              "        [0.69411767]],\n",
              "\n",
              "       [[0.9882353 ],\n",
              "        [0.9843137 ],\n",
              "        [0.9882353 ],\n",
              "        ...,\n",
              "        [0.37254903],\n",
              "        [0.46666667],\n",
              "        [0.5568628 ]],\n",
              "\n",
              "       [[0.9843137 ],\n",
              "        [0.9843137 ],\n",
              "        [0.9882353 ],\n",
              "        ...,\n",
              "        [0.32156864],\n",
              "        [0.39607844],\n",
              "        [0.42352942]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k-dwGgP_8k7",
        "outputId": "338ecd6e-b33f-4e43-c34a-029e3e46885f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_label[45]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShGBSm2w3gl0",
        "outputId": "2a2fe8cb-f70c-480c-d836-49f6b0bfcdb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_vali.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_K3hEzEU24N"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "                         keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1), padding='valid', activation='relu', input_shape=[200,200,1]),\n",
        "                         keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "                         keras.layers.Flatten(),\n",
        "                         keras.layers.Dense(units=128, activation='relu'),\n",
        "                         keras.layers.Dense(units=10, activation='softmax'),\n",
        "])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXGCvh1U0xlr"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoUmQZkn1t8-",
        "outputId": "502953c7-c64b-47e5-9190-e721ea408a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "model.fit(x_train, y_label, epochs=10, batch_size=100, validation_data=(x_vali, y_vali), verbose =1)\n",
        "print (\"training complete\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 16.8045 - accuracy: 0.1616 - val_loss: 17.8404 - val_accuracy: 0.1806\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 11s 3s/step - loss: 12.1472 - accuracy: 0.2247 - val_loss: 16.9366 - val_accuracy: 0.1944\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 4.6613 - accuracy: 0.6843 - val_loss: 12.6491 - val_accuracy: 0.1667\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.8996 - accuracy: 0.8157 - val_loss: 14.2268 - val_accuracy: 0.3472\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.8117 - accuracy: 0.8510 - val_loss: 12.5808 - val_accuracy: 0.2917\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1640 - accuracy: 0.9394 - val_loss: 12.6049 - val_accuracy: 0.1667\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.0686 - accuracy: 0.9697 - val_loss: 12.8940 - val_accuracy: 0.1667\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.0476 - accuracy: 0.9823 - val_loss: 13.1645 - val_accuracy: 0.1667\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 13.4545 - val_accuracy: 0.1667\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 13.7334 - val_accuracy: 0.1667\n",
            "training complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9thQX-P42Apm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}