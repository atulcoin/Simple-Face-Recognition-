{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final face project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfjaT70+k06YVbyHnExyK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atulcoin/Simple-Face-Recognition-/blob/master/final_face_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rskV1UqV3MM",
        "outputId": "d8abf4a8-f0a4-4e31-8e01-8b9c84af7c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "!pip install pafy\n",
        "!pip install imutils pafy youtube-dl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pafy\n",
            "  Downloading https://files.pythonhosted.org/packages/74/69/829919eeadff695338f98fa12bb99e45490761a2010c8d688d88b6df194a/pafy-0.5.5-py2.py3-none-any.whl\n",
            "Installing collected packages: pafy\n",
            "Successfully installed pafy-0.5.5\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
            "Requirement already satisfied: pafy in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
            "Collecting youtube-dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/b4/c83b577bfb1be7c88dff10eecd70650eca7729b25135345108ea676e6f3b/youtube_dl-2020.9.20-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2020.9.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZqZyWkYWLYV"
      },
      "source": [
        "import imutils\n",
        "import cv2\n",
        "import pafy\n",
        "import youtube_dl\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYmvK5crWXQ3"
      },
      "source": [
        "url = \"https://www.youtube.com/watch?v=hoNb6HuNmU0\"\n",
        "vPafy = pafy.new(url)\n",
        "\n",
        "play = vPafy.getbest(preftype=\"mp4\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0bEq-4oWbaY",
        "outputId": "f8d2d835-5637-43d3-f5fa-c2c96a9b5791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "cap = cv2.VideoCapture(play.url)\n",
        "print(cap.isOpened()) # if in cap we have entered wrong file path then it will give false else true\n",
        "while(cap.isOpened()):    # TO CAPTURE FRAMES OF CAMERA TO VIEW AS VIDEO \n",
        "  #  print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # TO PRINT HEIGHT or property OF THE FRAME \n",
        "  #  print(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # TO PRINT WIDTHE OF THE FRAME \n",
        "    face_dec = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "    ret, frame= cap.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # here i am printing gray image as output\n",
        "    faces = face_dec.detectMultiScale(gray, scaleFactor =1.05, minNeighbors=5)\n",
        "\n",
        "    for x,y,w,h in faces:\n",
        "        gray = cv2.rectangle(gray, (x,y), (x+w,y+h), (0,255,0),2)\n",
        "        cv2_imshow(gray)\n",
        "    if cv2.waitKey(1) == 13:  #13 is the asci code of enter key\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b27ccdfe26d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# here i am printing gray image as output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0t07z1Gn_38"
      },
      "source": [
        "training of model with custom data set\n",
        "**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91UpJplsrkJu",
        "outputId": "8310c2e5-4f28-4f5c-be75-c3029873b01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ads9PHyrW2xR"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "bpath = '/content/drive/My Drive/part1face2'\n",
        "image_dir = os.path.join(bpath, \"train\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1iUs8KRpKoM"
      },
      "source": [
        "data_label = []\n",
        "data_x = []\n",
        "\n",
        "#count = 0\n",
        "\n",
        "current_id=0\n",
        "label_id={}\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(image_dir):\n",
        "  for file in files:\n",
        "    if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
        "      label = os.path.basename(root).replace(\" \",\"-\").lower() #we can replace os.path.dirname(path) with root also\n",
        "      path = os.path.join(root,file)\n",
        "            #print(label,path)\n",
        "            \n",
        "      if not label in label_id:\n",
        "        label_id[label] = current_id\n",
        "        current_id +=1\n",
        "      id_= label_id[label]\n",
        "      print(id_)\n",
        "        #img = cv2.imread(path, 1)\n",
        "      pil_image=  Image.open(path).convert(\"L\") # L to convert image in grey pil image is used to tell sysetem that the file in location is image file\n",
        "      image_arra=  np.array(pil_image,\"uint8\")\n",
        "            #print(image_arra)\n",
        "            \n",
        "      data_label.append(id_)\n",
        "      data_x.append(image_arra)\n",
        "data_label = np.asarray(data_label, dtype=np.int32)\n",
        "data_x = np.asarray(data_x, dtype=np.int32)\n",
        "#model = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "#model.train(np.asarray(x_train), np.asarray(y_label))\n",
        "#with open(\"labels.pickle\", 'wb') as f:\n",
        "   # pickle.dump(label_id, f)\n",
        "print(\"train complete\")\n",
        "print(data_x)\n",
        "#model.save('save_face.xml')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWeW8J1itdIS",
        "outputId": "1e23ec4a-d52b-4434-b90d-6f5ffa998e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_x.shape , data_label.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 200, 200), (600,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIaRr6yPwlX6"
      },
      "source": [
        "data_x = data_x.astype('float32')\n",
        "#y_label =y_label.astype('float32')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYIJX8u-x2el"
      },
      "source": [
        "data_x /= 255\n",
        "#y_label /=255"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SwfogUpxlrh"
      },
      "source": [
        "i have split data sets into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeSigqCcwovM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_x, data_label, train_size=0.80, random_state=365)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dWysQeEwolB",
        "outputId": "296b8920-bfe4-4a2a-c173-876215c24bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, X_test.shape, "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((480, 200, 200), (120, 200, 200))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dckKa3Cyd5M"
      },
      "source": [
        "creating validation data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryaNDITGwoeA"
      },
      "source": [
        "X_train, X_vali, y_train, y_vali = train_test_split(X_train, y_train, train_size=0.80, random_state=365)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK6dmeyfwoT3",
        "outputId": "821920f1-21cb-46f8-f3ff-72ac6a09d794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape,X_test.shape,X_vali.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((384, 200, 200), (120, 200, 200), (96, 200, 200))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys_nSRlTwoKF",
        "outputId": "15700c30-da08-4daf-d394-c7ef34fb0816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[300]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvVNne0OwoBP"
      },
      "source": [
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_test = np.expand_dims(X_test, -1)\n",
        "X_vali = np.expand_dims(X_vali, -1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6aUlxtawny5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuhhlZwiwnje"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2BflpNywnPk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADVeTxUCx76u"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "import keras\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXGCvh1U0xlr"
      },
      "source": [
        "input_size = 400\n",
        "output_size = 6\n",
        "hidden_layer_size = 50\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(200, 200, 1)),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "       tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoUmQZkn1t8-",
        "outputId": "d4f6e672-f917-498e-b502-fac47420f8f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_vali, y_vali), verbose =2)\n",
        "print (\"training complete\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12/12 - 0s - loss: 2.0555 - accuracy: 0.5286 - val_loss: 0.4808 - val_accuracy: 0.9062\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.3592 - accuracy: 0.9062 - val_loss: 0.1327 - val_accuracy: 0.9896\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.1100 - accuracy: 0.9870 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.0564 - accuracy: 0.9922 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.0364 - accuracy: 0.9974 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.0304 - accuracy: 0.9974 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.0248 - accuracy: 0.9974 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.0205 - accuracy: 0.9974 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.0191 - accuracy: 0.9974 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "training complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeRooxaf2Rti",
        "outputId": "ce9940da-2b20-4766-9d5d-48de4263e244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 200, 200, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1-PZVp22Ukm"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "                         keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1), padding='valid', activation='relu', input_shape=[200,200,1]),\n",
        "                         keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                         keras.layers.Flatten(),\n",
        "                         keras.layers.Dense(units=128, activation='relu'),\n",
        "                         keras.layers.Dense(units=6, activation='softmax'),\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izj29gTp21kj",
        "outputId": "525eada1-f338-4423-9419-9ba1c7067f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 313632)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               40145024  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 40,146,118\n",
            "Trainable params: 40,146,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vif3nYA4FAX"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NbfPuSI6agW",
        "outputId": "682a4d0c-ec62-4744-f4ac-82aeb12bbf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=9, batch_size=100, verbose=1, validation_data=(X_vali, y_vali))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "4/4 [==============================] - 10s 2s/step - loss: 9.2205 - accuracy: 0.2578 - val_loss: 15.7396 - val_accuracy: 0.3646\n",
            "Epoch 2/9\n",
            "4/4 [==============================] - 7s 2s/step - loss: 10.3246 - accuracy: 0.3464 - val_loss: 7.1616 - val_accuracy: 0.5104\n",
            "Epoch 3/9\n",
            "4/4 [==============================] - 6s 2s/step - loss: 4.2781 - accuracy: 0.7188 - val_loss: 3.6501 - val_accuracy: 0.5625\n",
            "Epoch 4/9\n",
            "4/4 [==============================] - 6s 2s/step - loss: 1.5734 - accuracy: 0.7370 - val_loss: 0.3601 - val_accuracy: 0.8021\n",
            "Epoch 5/9\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.3691 - accuracy: 0.8333 - val_loss: 0.4078 - val_accuracy: 0.7917\n",
            "Epoch 6/9\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.2321 - accuracy: 0.9219 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
            "Epoch 7/9\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.1131 - accuracy: 0.9870 - val_loss: 0.0990 - val_accuracy: 0.9896\n",
            "Epoch 8/9\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.0690 - accuracy: 0.9948 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
            "Epoch 9/9\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2c53f94668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iPCqIPkBy5K"
      },
      "source": [
        "training accuracy is 100% may be of data set which i have used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIDmz7vD7RLu",
        "outputId": "4205d692-4a6e-42be-d064-e84a6edee169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.predict(np.expand_dims(X_test[0], axis=0)).round(2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99, 0.  , 0.  , 0.  , 0.  , 0.  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eECw0fhXCN3d",
        "outputId": "2d56d7e0-ef4f-490d-fff4-2ac840a0f29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.argmax(model.predict(np.expand_dims(X_test[55], axis=0)).round(2))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVGWXkAuCrPB",
        "outputId": "3694da9b-382a-45d7-88fb-0e01e7769e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_test[55]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gua-yIaqCvSt",
        "outputId": "f1ca24c9-6406-441c-c8f2-d50a3c067cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 167ms/step - loss: 0.0283 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.028307469561696053, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51rzn-zHDIm9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}